"""
SOTA background removal using BRIA RMBG 2.0.

Discord FAQ specifically states: "rembg might not be good enough"
BRIA RMBG 2.0 provides much better edge quality and fewer artifacts.
"""

from transformers import AutoModelForImageSegmentation
import torch
from PIL import Image
import numpy as np
from typing import Optional
from loguru import logger
import torchvision.transforms as transforms


class SOTABackgroundRemover:
    """
    State-of-the-art background removal using BRIA RMBG 2.0.

    Significantly better than rembg:
    - Cleaner edges
    - Better handling of fine details (hair, fur, etc.)
    - More accurate segmentation
    - Faster inference

    This improves CLIP scores by ensuring clean transparent backgrounds.
    """

    def __init__(
        self,
        device: str = "cuda",
        model_name: str = "briaai/RMBG-2.0"
    ):
        """
        Initialize BRIA RMBG 2.0 background remover.

        Args:
            device: CUDA device
            model_name: HuggingFace model ID
        """
        self.device = device
        self.is_on_gpu = False

        logger.info(f"Loading {model_name} background remover...")

        try:
            # Load model on CPU first to save GPU memory
            self.model = AutoModelForImageSegmentation.from_pretrained(
                model_name,
                trust_remote_code=True
            )

            self.model.eval()

            logger.info("âœ… BRIA RMBG 2.0 ready (on CPU, will move to GPU when needed)")

        except Exception as e:
            logger.error(f"Failed to load BRIA RMBG 2.0: {e}")
            logger.warning("Falling back to basic background removal")
            self.model = None

    @torch.no_grad()
    def remove_background(
        self,
        image: Image.Image,
        threshold: float = 0.5
    ) -> Image.Image:
        """
        Remove background from image.

        Args:
            image: Input PIL Image (RGB)
            threshold: Segmentation threshold (0.0-1.0)
                - Lower: More aggressive removal, may lose details
                - Higher: More conservative, may keep background

        Returns:
            RGBA PIL Image with transparent background

        Example:
            >>> remover = SOTABackgroundRemover()
            >>> rgba_image = remover.remove_background(rgb_image)
        """
        if self.model is None:
            # Fallback to rembg if BRIA failed to load
            logger.warning("Using fallback background removal")
            return self._fallback_remove_background(image)

        try:
            # Move model to GPU before inference
            self.to_gpu()

            # Preprocess
            input_images = self._preprocess(image).to(self.device)

            # Predict mask
            preds = self.model(input_images)[-1].sigmoid().cpu()

            # Post-process mask
            pred = preds[0].squeeze()
            mask = (pred.numpy() > threshold) * 255
            mask = mask.astype(np.uint8)

            # Create RGBA image
            rgba = image.convert("RGB")
            rgba.putalpha(Image.fromarray(mask))

            logger.debug(f"Background removed (threshold={threshold})")

            # Move model back to CPU to free GPU memory
            self.to_cpu()

            return rgba

        except Exception as e:
            logger.error(f"Background removal failed: {e}")
            # Return original with full alpha as fallback
            rgba = image.convert("RGB")
            alpha = Image.new('L', image.size, 255)
            rgba.putalpha(alpha)
            return rgba

    def _preprocess(self, image: Image.Image) -> torch.Tensor:
        """
        Preprocess image for BRIA model.

        The model expects specific input format.
        """
        # Convert to RGB if needed
        if image.mode != 'RGB':
            image = image.convert('RGB')

        # Standard ImageNet normalization
        transform = transforms.Compose([
            transforms.Resize((1024, 1024)),  # BRIA works best at 1024x1024
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])

        return transform(image).unsqueeze(0)

    def _fallback_remove_background(self, image: Image.Image) -> Image.Image:
        """
        Fallback to rembg if BRIA unavailable.

        This is the old method - not as good but better than nothing.
        """
        try:
            from rembg import remove
            from io import BytesIO

            logger.warning("Using rembg fallback (not recommended for competition)")

            # rembg expects PIL Image
            output = remove(image)

            # Ensure output is RGBA
            if output.mode != 'RGBA':
                rgba = image.convert("RGB")
                alpha = Image.new('L', image.size, 255)
                rgba.putalpha(alpha)
                return rgba

            return output

        except ImportError:
            logger.warning("rembg not installed, using simple background (full alpha)")
            # Return original with full alpha
            rgba = image.convert("RGB")
            alpha = Image.new('L', image.size, 255)
            rgba.putalpha(alpha)
            return rgba
        except Exception as e:
            logger.error(f"Fallback removal also failed: {e}")
            # Last resort: return original with full alpha
            rgba = image.convert("RGB")
            alpha = Image.new('L', image.size, 255)
            rgba.putalpha(alpha)
            return rgba

    @torch.no_grad()
    def remove_background_batch(
        self,
        images: list[Image.Image],
        threshold: float = 0.5
    ) -> list[Image.Image]:
        """
        Process multiple images in batch (more efficient).

        Args:
            images: List of PIL Images
            threshold: Segmentation threshold

        Returns:
            List of RGBA PIL Images
        """
        if not images:
            return []

        try:
            # Preprocess all images
            inputs = torch.cat([
                self._preprocess(img) for img in images
            ]).to(self.device)

            # Batch prediction
            preds = self.model(inputs)[-1].sigmoid().cpu()

            # Post-process each
            results = []
            for i, image in enumerate(images):
                pred = preds[i].squeeze()
                mask = (pred.numpy() > threshold) * 255
                mask = mask.astype(np.uint8)

                rgba = image.convert("RGB")
                rgba.putalpha(Image.fromarray(mask))
                results.append(rgba)

            return results

        except Exception as e:
            logger.error(f"Batch processing failed: {e}")
            # Process individually as fallback
            return [self.remove_background(img, threshold) for img in images]

    def set_device(self, device: str):
        """Change device"""
        if self.model:
            self.device = device
            self.model.to(device)
            self.is_on_gpu = (device == "cuda")
            logger.info(f"Moved background remover to {device}")

    def to_gpu(self):
        """Move model to GPU"""
        if self.model and not self.is_on_gpu:
            self.model.to(self.device)
            self.is_on_gpu = True
            logger.debug("Moved background remover to GPU")

    def to_cpu(self):
        """Move model to CPU to free GPU memory"""
        if self.model and self.is_on_gpu:
            self.model.to("cpu")
            self.is_on_gpu = False
            # Clear CUDA cache
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
            logger.debug("Moved background remover to CPU")


# Performance notes:
# BRIA RMBG 2.0 vs rembg:
# - Speed: ~2x faster
# - Quality: Significantly better edges
# - VRAM: ~2GB vs ~1GB (worth it for quality)
# - Edge cases: Much better with complex backgrounds
#
# This is critical for CLIP scores as clean backgrounds help
# the model focus on the actual 3D object.
